<!DOCTYPE html>
<html>
<head>
<title>AWS LAMP</title>
</head>
<link href="http://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
<link rel="stylesheet" href="http://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<style>
    body {
        font-family: 'Roboto', sans-serif;
        max-width:1200px;
        margin:0 auto;
    }
    img {
        border:3px solid black;
        margin:10px 10px;
        padding:0;
        max-width: 960px;
    }
    li {
        padding: 5px;
    }
    ol {
        list-style-type: lower-roman;
        list-style-position: inside;
    }
    .toc li {
        font-size:1.4em;
        list-style: none;
    }
    .cntr {
        text-align:center;
    }
    .eg {
        color: #080;
    }
    .highlight {
        background-color: #FF9;
    }
    code {
        font-family: monospace; 
        font-size: 1em;
        white-space: pre;
    }
    .codediv {
        padding: 10px;
        background-color: #ddd;
        margin: 0 65px;
        width: 750px;
        display: block;
        border: 1px solid black;
    }
    a, a:visited {
        text-decoration: none;
        color:#369;
    }
</style>
<body>


<h1 class='cntr'>AWS LAMP with IAM, RDS, EC2, S3, EFS, and AMI</h1>

<h2 id="contents">Contents</h2> 
    <ul class="toc">
        <li><a href="#introduction">Introduction</a></li>
        <li><a href="#glossary">Glossary</a></li>
        <li><a href="#step1">Step 1. Create Security Groups in the Main VPC</a></li>
        <li><a href="#step2">Step 2. Create an EFS Mount in the Main VPC</a></li>
        <li><a href="#step3">Step 3. Create a Public S3 Bucket</a></li>
        <li><a href="#step4">Step 4. Create an IAM Role for EC2 to access S3</a></li>
        <li><a href="#step5">Step 5. Create a MySQL RDS Database</a></li>
        <li><a href="#step6">Step 6. Create an EC2 Instance</a></li>
        <li><a href="#step7">Step 7. Configure the EC2 Instance</a></li>
        <li><a href="#step8">Step 8. Launch a new EC2 Instance from AMI</a></li>
        <li><a href="#conclusion">Conclusion</a></li>
    </ul>

<br><br>
<h2 id="introduction">Introduction</h2>
    <p>This demonstration expands the typical LAMP (Linux, Apache, MySQL, PHP) Stack to use AWS features to increase redundancy and resiliency.</p>

    <ul>
        <li>
            <b>EFS</b> --
                All files and directories are redundantly stored within and across multiple Availability Zones in a region to prevent the loss of data from the failure of any single component. The distributed architecture of Amazon EFS provides data protection from an AZ outage, system and component failures, and network connection errors.
        </li>
        <li> 
            <b>S3</b> --
                Objects are redundantly stored on multiple devices across multiple facilities in an Amazon S3 region. Amazon S3 also regularly verifies the integrity of data stored using checksums. If Amazon S3 detects data corruption, it is repaired using redundant data. In addition, Amazon S3 calculates checksums on all network traffic to detect corruption of data packets when storing or retrieving data.
        </li>
        <li>
            <b>RDS</b> --
                When you provision a Multi-AZ DB Instance, Amazon RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone (AZ). Each AZ runs on its own physically distinct, independent infrastructure, and is engineered to be highly reliable. In case of an infrastructure failure, Amazon RDS performs an automatic failover to the standby, so that you can resume database operations as soon as the failover is complete. Since the endpoint for your DB Instance remains the same after a failover, your application can resume database operation without the need for manual administrative intervention.

        </li>         
    </ul>

    <p>Although the code in this example is relatively simple, the same mechanisms can be used for sites using CMS systems like Drupal or Wordpress.</p>
    <p>When OIT provision an account in AWS, we create a <em>Main</em> VPC (virtual private cloud) divided into a number of subnets. We categorize those subnets as follows:
        <ul>
            <li>Public - resources placed in these subnets are accessible from the Internet.</li>
            <li>Private - resources placed in these subnets have Internet access via NAT (network address translation) but are not visible from the Internet.</li>
            <li>Data - resources placed in these subnets have no access to or from the Internet.</li>
        </ul>
        More than one subnet is created in each category, and are placed in different availability zones (AZs). An Availability Zone is an AWS data center (or group of data centers) that is geographically isolated from other AZs in a Region.
    </p>


<br><br>
<h2 id="glossary">Glossary</h2>
    <p>
        <h4>RDS</h4>
        Amazon Relational Database Service (Amazon RDS) makes it easy to set up, operate, and scale a relational database in the cloud. It provides cost-efficient and resizable capacity while automating time-consuming administration tasks such as hardware provisioning, database setup, patching and backups. It frees you to focus on your applications so you can give them the fast performance, high availability, security and compatibility they need. [<a href='https://aws.amazon.com/rds/'>https://aws.amazon.com/rds/</a>]
    </p>
    <p>
        <h4>EC2</h4>
        Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. [<a href='https://aws.amazon.com/ec2/'>https://aws.amazon.com/ec2/</a>]
    </p>
    <p>
        <h4>S3</h4>
        Amazon Simple Storage Service (Amazon S3) is the largest and most performant, secure, and feature-rich object storage service. With Amazon S3, organizations of all sizes and industries can store any amount of data for any use case, including applications, IoT, data lakes, analytics, backup and restore, archive, and disaster recovery. Amazon S3 is designed for 99.999999999% durability to protect data from site-level failures, errors, and threats, so that it is available to your end users and applications at all times. [<a href='https://aws.amazon.com/s3/'>https://aws.amazon.com/s3/</a>]
    </p>
    <p>
        <h4>EFS</h4>
        Amazon Elastic File System (Amazon EFS) provides a simple, scalable, elastic file system for Linux-based workloads for use with AWS Cloud services and on-premises resources. It is built to scale on demand to petabytes without disrupting applications, growing and shrinking automatically as you add and remove files, so your applications have the storage they need â€“ when they need it. It is designed to provide massively parallel shared access to thousands of Amazon EC2 instances, enabling your applications to achieve high levels of aggregate throughput and IOPS with consistent low latencies. Amazon EFS is a fully managed service that requires no changes to your existing applications and tools, providing access through a standard file system interface for seamless integration. [<a href='https://aws.amazon.com/efs/'>https://aws.amazon.com/efs/</a>]
    </p>
    <p>
        <h4>IAM</h4>
        AWS Identity and Access Management (IAM) enables you to manage access to AWS services and resources securely. Using IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources.  [<a href='https://aws.amazon.com/iam/'>https://aws.amazon.com/iam/</a>]
    </p>


<br><br>
<h2 id="step1">Step 1. Create Security Groups in the Main VPC</h2>
    <p>In order for traffic to reach our resources, we need to create two security groups. (<i class="fas fa-exclamation-triangle"></i> We are placing our resources in the Main VPC; make sure when creating your Security Groups they are also created in the Main VPC)
    </p>
    <ol>
        <li>Create a Security Group with port 22 [SSH] access from BYU and port 80 [HTTP] access from anywhere.
            <br><a href='sg-01.png'><img src='sg-01.png'></a>
        </li>
        <li>Create a Self Referencing Security Group with port 3306 [MYSQL/Aurora] and port 2049 [NFS] access.
            <br><a href='sg-02.png'><img src='sg-02.png'></a>
        </li>
    </ol>
    <p>Security Group inbound rules can be thought of as 1) <em>WHAT</em> are we giving access to, and 2) <em>WHO</em> are we giving that access to.</p>
    <p>We will add the Self Referencing group to our EFS Mount and our DB Instance because they have the <em>WHAT</em>. 
        We will add it to our EC2 instances to make them the <em>WHO</em>.</p>

<br><br>
<h2 id="step2">Step 2. Create an EFS Mount in the Main VPC</h2>
    <p>EFS is a Network File System (NFS) that we can attach to as many virtual machines (EC2 instances) as we need. This will enable all of our EC2 instances to operate off of the same code base.</p>
    <p>Create the EFS in the same subnets as the EC2 instances that will use it. (<i class="fas fa-exclamation-triangle"></i> In our case, the two Public subnets)</p>
    <p>Attach the Self Referencing Security Group.
    <a href='efs-01.png'><img src='efs-01.png'></a>

<br><br>
<h2 id="step3">Step 3. Create a Public S3 Bucket</h2>
    <p>Our code will take uploaded files and store them and reference them from an S3 Bucket.</p>
    <ol>
        <li>Create an S3 Bucket named <em>kempy-bootcamp-bucket</em> (<i class="fas fa-exclamation-triangle"></i> S3 Bucket names must be unique throughout all AWS)
            <br><a href='s3-01.png'><img src='s3-01.png'></a>
        </li>
        <li>Turn off the Public blocks (<i class="fas fa-exclamation-triangle"></i> We need it to be a Public Bucket)
            <br><a href='s3-02.png'><img src='s3-02.png'></a>
        </li>
        <li>Add a public read access policy
            <br><a href='s3-03.png'><img src='s3-03.png'></a>
        </li>
    </ol>
    <div class='codediv'>
        <code>
    {
      "Version":"2012-10-17",
      "Statement":[
        {
          "Sid":"AddPerm",
          "Effect":"Allow",
          "Principal": "*",
          "Action":["s3:GetObject"],
          "Resource":["arn:aws:s3:::kempy-bootcamp-bucket/*"]
        }
      ]
    }
        </code>
    </div>


<br><br>
<h2 id="step4">Step 4. Create an IAM Role for EC2 to access S3</h2>
    <p>Uploading to an S3 bucket requires permissions. These permissions can be granted by creating an IAM User and hard coding the user keys into our application. A more secure way of granting this access is
    by creating an S3 Access Role and attaching that role to our EC2 instances.</p>
    <ol>
        <li>Create an IAM Role <em>kempy-s3-access</em>
            <br><a href='iam-01.png'><img src='iam-01.png'></a>
        </li>
        <li>Attach an inline policy (<em>kempy-inline-bucket-policy</em>) with access to our S3 Bucket
            <br><a href='iam-02.png'><img src='iam-02.png'></a>
        </li>
    </ol>
    <div class='codediv'>
        <code>
    {
        "Version": "2012-10-17",
        "Statement": [
            {
                "Sid": "VisualEditor0",
                "Effect": "Allow",
                "Action": "s3:*",
                "Resource": [
                    "arn:aws:s3:::kempy-bootcamp-bucket/*",
                    "arn:aws:s3:::kempy-bootcamp-bucket"
                ]
            }
        ]
    }
        </code>
    </div>


<br><br>
<h2 id="step5">Step 5. Create a MySQL RDS Database</h2>

    <ol>
        <li>Create a MySQL DB with a replica in a different AZ
            <br><a href='rds-01.png'><img src='rds-01.png'></a>
        </li>
        <li>Name the DB Instance and create a master username and password
            <br><a href='rds-02.png'><img src='rds-02.png'></a>
        </li>
        <li>Place our DB Instance in the Main VPC in the main-db-subnet-group. Attach the Self Referencing Security Group.
            <br><a href='rds-03.png'><img src='rds-03.png'></a>
        </li>
        <li>Once the instance is created, take note of the instance end-point. [kempy-mysql.crzc9xds3qkq.us-west-2.rds.amazonaws.com]
            <br><a href='rds-04.png'><img src='rds-04.png'></a>
        </li>
    </ol>

    
<br><br>
<h2 id="step6">Step 6. Create an EC2 Instance</h2>
    <p><i class="fas fa-exclamation-triangle"></i> I came across a few gotchas when creating the EC2 instance; mainly due to the AWS PHP SDK (the code used by PHP to connect with AWS resources via their API).
    <br>The most up-to-date SDK requires at least PHP 5.5, but the first AMI (Amazon Machine Images) I used defaulted to PHP 5.4.</p>

    <ol>
        <li>Launch an EC2 Instance (from a PHP 5.5 compatible AMI) [Amazon Linux AMI 2018.03.0 (HVM), SSD Volume Type - ami-01e24be29428c15b2]
            <br><a href='ec2-01.png'><img src='ec2-01.png'></a>
        </li>
        <li>Add it to a Public Subnet in the Main VPC
            <br><a href='ec2-02.png'><img src='ec2-02.png'></a>
        </li>
        <li>Add the Security Group we created earlier - we'll also need to attach the 2nd security group (the self referencing one) but can only attach one when we create the instance.
            <br><a href='ec2-03.png'><img src='ec2-03.png'></a>
        </li>
        <li>Attach the Self Referencing Security Group
            <br><a href='ec2-04.png'><img src='ec2-04.png'></a>
            <br><a href='ec2-05.png'><img src='ec2-05.png'></a>
        </li>
        <li>Attach the IAM Role
            <br><a href='ec2-06.png'><img src='ec2-06.png'></a>
            <br><a href='ec2-07.png'><img src='ec2-07.png'></a>
        </li>
    </ol>

   
<br><br>
<h2 id="step7">Step 7. Configure the EC2 Instance</h2>
    
    <ol>
        <li>Update the instance and install the required software - Apache (httpd), PHP 5.5, MySQL (to access our database) 
            <br><br>
    <div class='codediv'>
        <code>
sudo yum update -y 

sudo yum -y install httpd24
sudo yum -y install php55 php55-mysqlnd php55-xml php55-mcrypt php55-mbstring php55-cli php55-gd
sudo yum -y install mysql

sudo chkconfig httpd on
sudo service httpd start
        </code>
    </div>


        </li>
        <li>Connect to MySQL RDS Instance and create a database, database user, and a table for our application. 
            <br><a href='config-mysql.png'><img src='config-mysql.png'></a>
            <br><br>
    <div class='codediv'>
        <code>
mysql -h kempy-mysql.crzc9xds3qkq.us-west-2.rds.amazonaws.com -u iamgroot -p

CREATE DATABASE mydb;
CREATE USER 'dbuser'@'%';
SET PASSWORD FOR 'dbuser'@'%'=PASSWORD("XesAchollPanancedBleInts");
GRANT ALL PRIVILEGES ON mydb.* TO 'dbuser'@'%' IDENTIFIED BY 'XesAchollPanancedBleInts';

CREATE TABLE mydb.images (
  id int NOT NULL AUTO_INCREMENT,
  image_name varchar(255) DEFAULT NULL,
  image_type varchar(255) DEFAULT NULL,
  image_s3_key varchar(255) DEFAULT NULL,
  image_s3_url varchar(255) DEFAULT NULL,
  thumb_s3_key varchar(255) DEFAULT NULL,
  thumb_s3_url varchar(255) DEFAULT NULL,
  description varchar(2048) DEFAULT NULL,
  PRIMARY KEY (id)
);
        </code>
    </div>

        </li>
        <li>Create a new group and add the ec2-user user to it. Change the ownership of the web (/var/www) directory.
            <br><br>
    <div class='codediv'>
        <code>
sudo groupadd web
sudo usermod -a -G web ec2-user

sudo chown -R apache:web /var/www
sudo find /var/www -type d -exec chmod u=rwx,g=rwxs,o=xr '{}' \;
sudo find /var/www -type f -exec chmod u=rw,g=rw,o=r '{}' \;
        </code>
    </div>
        </li>
        <li>Mount the EFS file system at the web root /var/www/html
            <br><br>
    <div class='codediv'>
        <code>
sudo yum install -y amazon-efs-utils
sudo mount -t efs fs-7a0022d2:/ /var/www/html

#Add the mount to the fstab to allow persistence on reboots
sudo vim /etc/fstab
    #Add the following line to the fstab  
    fs-7a0022d2:/ /var/www/html efs defaults,_netdev 0 0
        </code>
    </div>
        </li>
        <li>Install Composer, and use it to install the AWS SDK PHP
            <br><a href='composer.png'><img src='composer.png'></a>
            <br><br>
    <div class='codediv'>
        <code>
cd ~
curl -sS https://getcomposer.org/installer | php
sudo mv composer.phar /usr/local/bin/composer

cd /var/www/html
/usr/local/bin/composer require aws/aws-sdk-php
        </code>
    </div>
        </li>
        <li>Edit the php.ini file to allow for bigger file uploads
        <br><br>
    <div class='codediv'>
        <code>
sudo vim /etc/php.ini
    # Edit the following lines
    upload_max_filesize = 32M
    post_max_size = 32M

sudo service httpd restart
        </code>
    </div>

        </li>
        <li>Upload 
            <em><a href='https://github.com/michaelkemp/aws-bootcamp-rds-ec2-s3-efs/blob/master/index.php'>index.php</a></em> and 
            <em><a href='https://github.com/michaelkemp/aws-bootcamp-rds-ec2-s3-efs/blob/master/upload.php'>upload.php</a></em>
            to the /var/www/html diectory. Create an 'images' folder as a temporary storage location for the images we upload. 
        <br><a href='dir.png'><img src='dir.png'></a>
        </li>
        <li>Test at http://ec2-34-217-206-91.us-west-2.compute.amazonaws.com/ (<i class="fas fa-exclamation-triangle"></i> will be deleted after the Bootcamp)
        </li>
     </ol>   

<br><br>
<h2 id="step8">Step 8. Launch a new EC2 Instance from AMI</h2>
    <p>Now we have an EC2 Instance set up the way we want it, we can use it to create duplicates. This is a best practice for reducing mean time to recovery (MTTR).</p>

    <ol>
        <li>Create an Image from our EC2 Instance
            <br><a href='image-01.png'><img src='image-01.png'></a>
        </li>
        <li>Give it a name
            <br><a href='image-02.png'><img src='image-02.png'></a>
        </li>
        <li>Launch a new EC2 Instance from the AMI we just created
            <br><a href='image-03.png'><img src='image-03.png'></a>
        </li>
        <li>Add it to the Main VPC and Public Subnet. <i class="fas fa-exclamation-triangle"></i> Once the instance has initialized, add the Self Referencing Security Group and IAM Role.
            <br><a href='image-04.png'><img src='image-04.png'></a>
        </li>
        <li>Test the new EC2 at http://ec2-52-12-15-153.us-west-2.compute.amazonaws.com/ (<i class="fas fa-exclamation-triangle"></i> will be deleted after the Bootcamp)
        </li>
    </ol>


<br><br>
<h2 id="conclusion">Conclusion</h2>
    <p>In this example, we set up 2 EC2 instances in Public facing subnets. If we were to create this in a production environment, we could further protect our web servers by placing them in the Private subnet, and directing traffic to them via a Load Balancer in the public subnet.</p>
    <p>In this way, the Load Balancer could monitor the health of our EC2 instances and redirect traffic as needed.</p>
<br><br>

</body>
</html>



